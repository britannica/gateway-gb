continue..
be complete and we must know how to choose. But it may happen that we have passed by circumstances which at first sight seemed completely foreign to the foreseen happening, to which one would never have dreamed of attributing any influence and which nevertheless, contrary to all anticipation, come to play an important role. A man passes in the street going to his business; some one knowing the business could have told why he started at such a time and went by such a street. On the roof works a tiler. The contractor employing him could in a certain measure foresee what he would do. But the passer-by scarcely thinks of the tiler, nor the tiler of him; they seem to belong to two worlds completely foreign to one another. And yet the tiler drops a tile which kills the man, and we do not hesitate to say this is chance. Our weakness forbids our considering the entire universe and makes us cut it up into slices. We try to do this as little artificially as possible. And yet it happens from time to time that two of these slices react upon each other. The effects of this mutual action then seem to us to be due to chance. Is this a third way of conceiving chance? Not always; in fact most often we are carried back to the first or the second. Whenever two worlds usually foreign to one another come thus to react upon each other, the laws of this reaction must be very complex. On the other hand, a very slight change in the initial conditions of these two worlds would have been sufficient for the reaction not to have happened. How little was needed for the man to pass a second later or the tiler to drop his tile a second sooner. All we have said still does not explain why chance obeys laws. Does the fact that the causes are slight or complex suffice for our foreseeing, if not their effects in each case, at least what their effects will be, on the average? To answer this question we had better take up again some of the examples already cited. I shall begin with that of the roulette. I have said that the point where the needle will stop depends upon the initial push given it. What is the probability of this push having this or that value? I know nothing about it, but it is difficult for me not to suppose that this probability is represented by a continuous analytic function. The probability that the push is comprised between α and α+∈ will then be sensibly equal to the probability of its being comprised between α+∈ and α+2∈, provided ∈ be very small. This is a property common to all analytic functions. Minute variations of the function are proportional to minute variations of the variable. But we have assumed that an exceedingly slight variation of the push suffices to change the color of the sector over which the needle finally stops. From α to α+∈ it is red, from α+∈ to α+2∈ it is black; the probability of each red sector is therefore the same as of the following black, and consequently the total probability of red equals the total probability of black. The datum of the question is the analytic function representing the probability of a particular initial push. But the theorem remains true whatever be this datum, since it depends upon a property common to all analytic functions. From this it follows finally that we no longer need the datum. What we have just said for the case of the roulette applies also to the example of the minor planets. The zodiac may be regarded as an immense roulette on which have been tossed many little balls with different initial impulses varying according to some law. Their present distribution is uniform and independent of this law, for the same reason as in the preceding case. Thus we see why phenomena obey the laws of chance when slight differences in the causes suffice to bring on great differences in the effects. The probabilities of these slight differences may then be regarded as proportional to these differences themselves, just because these differences are minute, and the infinitesimal increments of a continuous function are proportional to those of the variable. Take an entirely different example, where intervenes especially the complexity of the causes. Suppose a player shuffles a pack of cards. At each shuffle he changes the order of the cards, and he may change them in many ways. To simplify the exposition, consider only three cards. The cards which before the shuffle occupied respectively the places 123, may after the shuffle occupy the places 123, 231, 312, 321, 132, 213. Each of these six hypotheses is possible and they have respectively for probabilities: p 1 , p 2 , p 3 , p 4 , p 5 , p 6 . The sum of these six numbers equals 1; but this is all we know of them; these six probabilities depend naturally upon the habits of the player which we do not know. At the second shuffle and the following, this will recommence, and under the same conditions; I mean that p for example represents always the probability that the three cards which occupied after the nth shuffle and before n+1th the places 123, occupy the places 321 after the n+1th shuffle. And this remains true whatever be the number n, since the habits of the player and his way of shuffling remain the same. But if the number the shuffles is very great, the cards which before the first shuffle occupied the places 123 may, after the last shuffle, occupy the places 123, 231, 312, 321, 132, 213 and the probability of these six hypotheses will be sensibly the same and equal to 1/6; and this will be true whatever be the numbers p…p which we do not know. The great number of shuffles, that is to say the complexity of the causes, has produced uniformity. This would apply without change if there were more than three cards, but even with three cards the demonstration would be complicated; let it suffice to give it for only two cards. Then we have only two possibilities 12, 21 with the probabilities p and p=1−p. Suppose n shuffles and suppose I win one franc if the cards are finally in the initial order and lose one if they are finally inverted. Then, my mathematical expectation will be (p−p). The difference p−p is certainly less than 1; so that if n is very great my expectation will be zero; we need not learn p and p to be aware that the game is equitable. There would always be an exception if one of the numbers p and p was equal to 1 and the other naught. Then it would not apply because our initial hypotheses would be too simple. What we have just seen applies not only to the mixing of cards, but to all mixings, to those of powders and of liquids, and even to those of the molecules of gases in the kinetic theory of gases. To return to this theory, suppose for a moment a gas whose molecules cannot mutually clash, but may be deviated by hitting the insides of the vase wherein the gas is confined. If the form of the vase is sufficiently complex the distribution of the molecules and that of the velocities will not be long in becoming uniform. But this will not be so if the vase is spherical or if it has the shape of a cuboid. Why? Because in the first case the distance from the center to any trajectory will remain constant; in the second case this will be the absolute value of the angle of each trajectory with the faces of the cuboid. So we see what should be understood by conditions too simple; they are those which conserve something, which leave an invariant remaining. Are the differential equations of the problem too simple for us to apply the laws of chance? This question would seem at first view to lack precise meaning; now we know what it means. They are too simple if they conserve something, if they admit a uniform integral. If something in the initial conditions remains unchanged, it is clear the final situation can no longer be independent of the initial situation. We come finally to the theory of errors. We know not to what are due the accidental errors, and precisely because we do not know, we are aware they obey the law of Gauss. Such is the paradox. The explanation is nearly the same as in the preceding cases. We need know only one thing: that the errors are very numerous, that they are very slight, that each may be as well negative as positive. What is the curve of probability of each of them? We do not know;