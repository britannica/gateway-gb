Work: Mathematics and Metaphysicians Field: mathematics and metaphysicians Author: Bertrand Russell The nineteenth century, which prided itself upon the invention of steam and evolution, might have derived a more legitimate title to fame from the discovery of pure mathematics. This science, like most others, was baptised long before it was born; and thus we find writers before the nineteenth century alluding to what they called pure mathematics. But if they had been asked what this subject was, they would only have been able to say that it consisted of Arithmetic, Algebra, Geometry, and so on. As to what these studies had in common, and as to what distinguished them from applied mathematics, our ancestors were completely in the dark. Pure mathematics was discovered by Boole, in a work which he called the Laws of Thought (1854). This work abounds in asseverations that it is not mathematical, the fact being that Boole was too modest to suppose his book the first ever written on mathematics. He was also mistaken in supposing that he was dealing with the laws of thought: the question how people actually think was quite irrelevant to him, and if his book had really contained the laws of thought, it was curious that no one should ever have thought in such a way before. His book was in fact concerned with formal logic, and this is the same thing as mathematics. Pure mathematics consists entirely of assertions to the effect that, if such and such a proposition is true of anything, then such and such another proposition is true of that thing. It is essential not to discuss whether the first proposition is really true, and not to mention what the anything is, of which it is supposed to be true. Both these points would belong to applied mathematics. We start, in pure mathematics, from certain rules of inference, by which we can infer that if one proposition is true, then so is some other proposition. These rules of inference constitute the major part of the principles of formal logic. We then take any hypothesis that seems amusing, and deduce its consequences. If our hypothesis is about anything, and not about some one or more particular things, then our deductions constitute mathematics. Thus mathematics may be defined as the subject in which we never know what we are talking about, nor whether what we are saying is true. People who have been puzzled by the beginnings of mathematics will, I hope, find comfort in this definition, and will probably agree that it is accurate. As one of the chief triumphs of modern mathematics consists in having discovered what mathematics really is, a few more words on this subject may not be amiss. It is common to start any branch of mathematics—for instance, Geometry—with a certain number of primitive ideas, supposed incapable of definition, and a certain number of primitive propositions or axioms, supposed incapable of proof. Now the fact is that, though there are indefinables and indemonstrables in every branch of applied mathematics, there are none in pure mathematics except such as belong to general logic. Logic, broadly speaking, is distinguished by the fact that its propositions can be put into a form in which they apply to anything whatever. All pure mathematics—Arithmetic, Analysis, and Geometry—is built up by combinations of the primitive ideas of logic, and its propositions are deduced from the general axioms of logic, such as the syllogism and the other rules of inference. And this is no longer a dream or an aspiration. On the contrary, over the greater and more difficult part of the domain of mathematics, it has been already accomplished; in the few remaining cases, there is no special difficulty, and it is now being rapidly achieved. Philosophers have disputed for ages whether such deduction was possible; mathematicians have sat down and made the deduction. For the philosophers there is now nothing left but graceful acknowledgments. The subject of formal logic, which has thus at last shown itself to be identical with mathematics, was, as every one knows, invented by Aristotle, and formed the chief study (other than theology) of the Middle Ages. But Aristotle never got beyond the syllogism, which is a very small part of the subject, and the schoolmen never got beyond Aristotle. If any proof were required of our superiority to the mediaeval doctors, it might be found in this. Throughout the Middle Ages, almost all the best intellects devoted themselves to formal logic, whereas in the nineteenth century only an infinitesimal proportion of the world’s thought went into this subject. Nevertheless, in each decade since 1850 more has been done to advance the subject than in the whole period from Aristotle to Leibniz. People have discovered how to make reasoning symbolic, as it is in Algebra, so that deductions are effected by mathematical rules. They have discovered many rules besides the syllogism, and a new branch of logic, called the Logic of Relatives, has been invented to deal with topics that wholly surpassed the powers of the old logic, though they form the chief contents of mathematics. It is not easy for the lay mind to realize the importance of symbolism in discussing the foundations of mathematics, and the explanation may perhaps seem strangely paradoxical. The fact is that symbolism is useful because it makes things difficult. (This is not true of the advanced parts of mathematics, but only of the beginnings.) What we wish to know is, what can be deduced from what. Now, in the beginnings, everything is self-evident; and it is very hard to see whether one self-evident proposition follows from another or not. Obviousness is always the enemy to correctness. Hence we invent some new and difficult symbolism, in which nothing seems obvious. Then we set up certain rules for operating on the symbols, and the whole thing becomes mechanical. In this way we find out what must be taken as premiss and what can be demonstrated or defined. For instance, the whole of Arithmetic and Algebra has been shown to require three indefinable notions and five indemonstrable propositions. But without a symbolism it would have been very hard to find this out. It is so obvious that two and two are four, that we can hardly make ourselves sufficiently sceptical to doubt whether it can be proved. And the same holds in other cases where self-evident things are to be proved. But the proof of self-evident propositions may seem, to the uninitiated, a somewhat frivolous occupation. To this we might reply that it is often by no means self-evident that one obvious proposition follows from another obvious proposition; so that we are really discovering new truths when we prove what is evident by a method which is not evident. But a more interesting retort is that, since people have tried to prove obvious propositions, they have found that many of them are false. Self-evidence is often a mere will-o’-the-wisp, which is sure to lead us astray if we take it as our guide. For instance, nothing is plainer than that a whole always has more terms than a part, or that a number is increased by adding one to it. But these propositions are now known to be usually false. Most numbers are infinite, and if a number is infinite you may add ones to it as long as you like without disturbing it in the least. One of the merits of a proof is that it instils a certain doubt as to the result proved; and when what is obvious can be proved in some cases, but not in others, it becomes possible to suppose that in these other cases it is false. The great master of the art of formal reasoning, among the men of our own day, is an Italian, Professor Peano, of the University of Turin. He has reduced the greater part of mathematics (and he or his followers will, in time, have reduced the whole) to strict symbolic form, in which there are no words at all. In the ordinary mathematical books, there are no doubt fewer words than most readers would wish. Still, little phrases occur, such as therefore, let us assume, consider, or hence it follows. All these, however, are a concession, and are swept away by Professor Peano. For instance, if we wish to learn the whole of Arithmetic, Algebra, the Calculus, and indeed all that is usually called pure mathematics (except Geometry), we must start with a dictionary of three words. One symbol stands for zero, another for number, and a third for next after. What these ideas mean, it is necessary to know if you wish to become an arithmetician. But after symbols have been invented for these three ideas, not another word is required in the whole development. All future symbols are symbolically explained by means of these three. Even these three can be explained by means of the notions of relation and class; but this requires the Logic of